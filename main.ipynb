{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of driving behavior using acc. data\n",
    "\n",
    "This notebooks uses the driving behavior dataset from Kaggle and aims to classify the driver's driving based on accelerometer data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from scipy import integrate\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "df = pd.read_csv('datasets/train_motion_data.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceleration vs Time\n",
    "plt.plot(df['Timestamp'], df['AccX'])\n",
    "plt.plot(df['Timestamp'], df['AccY'])\n",
    "plt.plot(df['Timestamp'], df['AccZ'])\n",
    "\n",
    "plt.legend(['X', 'Y', 'Z'])\n",
    "plt.title('Acceleration vs Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is clean with no null values. Becuase we are working with time-dependent physiscal measurements, we will not be removing the outliers as they carry important information regarding the driving at that moment in time.\n",
    "\n",
    "From the plot, we can identify 4 distinct measurements and will analyse them separately.\n",
    "\n",
    "We will divide the dataset into its 4 independent time frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifying time stops\n",
    "(df[['Timestamp']].diff() > 1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three time stops indicate 4 time slots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indeces for time windows\n",
    "time_index = df[(df[['Timestamp']].diff() > 1)['Timestamp']].index\n",
    "time_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dfs\n",
    "df_1 = df.iloc[0:time_index[0], :]\n",
    "df_1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dfs\n",
    "df_2 = df.iloc[time_index[0]:time_index[1], :]\n",
    "df_2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dfs\n",
    "df_3 = df.iloc[time_index[1]:time_index[2], :]\n",
    "df_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dfs\n",
    "df_4 = df.iloc[time_index[2]:, :]\n",
    "df_4.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# velocity XYZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enriching dataset\n",
    "\n",
    "We will calculate more physical parameters from the available data such as: acceleration norm, jerk, velocity, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acceleration norm\n",
    "dfs = [df_1, df_2, df_3, df_4]\n",
    "\n",
    "for dataframe in dfs:\n",
    "    acc = np.sqrt(dataframe.loc[:,'AccX']**2 + dataframe.loc[:,'AccY']**2 + dataframe.loc[:,'AccZ']**2)\n",
    "    dataframe.loc[:,'Acc'] = acc\n",
    "    dataframe = dataframe.reindex(sorted(dataframe.columns), axis=1)\n",
    "    display(dataframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jerk\n",
    "for dataframe in dfs:\n",
    "    jerkx = np.gradient(dataframe.loc[:,'AccX'])\n",
    "    jerky = np.gradient(dataframe.loc[:,'AccY'])\n",
    "    jerkz = np.gradient(dataframe.loc[:,'AccZ'])\n",
    "    dataframe.loc[:,'JerkX'] = jerkx\n",
    "    dataframe.loc[:,'JerkY'] = jerky\n",
    "    dataframe.loc[:,'JerkZ'] = jerkz\n",
    "    dataframe.loc[:,'Jerk'] = np.sqrt(dataframe.loc[:,'JerkX']**2 + dataframe.loc[:,'JerkY']**2 + dataframe.loc[:,'JerkZ']**2)\n",
    "    dataframe = dataframe.reindex(sorted(dataframe.columns), axis=1)\n",
    "    display(dataframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#velocity\n",
    "for dataframe in dfs:\n",
    "    vx = integrate.cumulative_trapezoid(dataframe.loc[:,'AccX'], initial=0)\n",
    "    vy = integrate.cumulative_trapezoid(dataframe.loc[:,'AccY'], initial=0)\n",
    "    vz = integrate.cumulative_trapezoid(dataframe.loc[:,'AccZ'], initial=0)\n",
    "    dataframe.loc[:,'VelX'] = vx\n",
    "    dataframe.loc[:,'VelY'] = vy\n",
    "    dataframe.loc[:,'VelZ'] = vz\n",
    "    dataframe.loc[:,'Vel'] = np.sqrt(dataframe.loc[:,'VelX']**2 + dataframe.loc[:,'VelY']**2 + dataframe.loc[:,'VelZ']**2)\n",
    "    dataframe = dataframe.reindex(sorted(dataframe.columns), axis=1)\n",
    "    display(dataframe.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(integrate.cumulative_trapezoid(df_1.loc[:,'AccX']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_1.loc[:,'AccX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "driving_behavior",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
